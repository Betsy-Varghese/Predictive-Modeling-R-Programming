{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>0. Project Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIM\n",
    "To predict if a customer will subscribe to a bank deposit or not\n",
    "\n",
    "### METHODOLOGY\n",
    "1. Pre-processing the data and creating the final base table \n",
    "2. To further split the training data into train and validation\n",
    "3. Hyper-parameter tuning\n",
    "4. Model Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> 1. Libraries and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'kknn' was built under R version 3.6.3\"\n",
      "Attaching package: 'kknn'\n",
      "\n",
      "The following object is masked from 'package:caret':\n",
      "\n",
      "    contr.dummy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Sys.setenv(LANG = \"en\")\n",
    "\n",
    "# Data processing library\n",
    "library(data.table)       # Data manipulation\n",
    "library(dplyr)            # Data manipulation\n",
    "library(plyr)             # Data manipulation\n",
    "library(stringr)          # String, text processing\n",
    "library(vita)             # Quickly check variable importance\n",
    "library(dataPreparation)  # Data preparation library\n",
    "library(woeBinning)       # Decision treeâ€“based binning for numerical and categorical variables\n",
    "library(Boruta)           # Variable selection\n",
    "library(imbalance)\n",
    "library(DescTools)\n",
    "library(mefa4)            #for 'notin' operator\n",
    "\n",
    "# Machine Learning Libraries\n",
    "library(mlr)           # Machine learning framework\n",
    "library(caret)         # Data processing and machine learning framework\n",
    "library(MASS)          # LDA\n",
    "library(randomForest)  # RF\n",
    "library(gbm)           # Boosting Tree\n",
    "library(xgboost)       # XGboost\n",
    "library(kknn)          # K-Nearest Neighbours\n",
    "library(ROCR)          # Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## <center> 2. Creation of Base Table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importing the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read train (full), test (holdout)\n",
    "data <- read.csv(\"C:/Users/bvarghese/Desktop/IESEG Slides/Statistical Learning- Minh Phan/In-class Kaggle Competition/data/Kaggle/input/bank_mkt_train.csv\")  # Training dataset\n",
    "predict <- read.csv(\"C:/Users/bvarghese/Desktop/IESEG Slides/Statistical Learning- Minh Phan/In-class Kaggle Competition/data/Kaggle/input/bank_mkt_test.csv\") # Holdout data set without responsea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Inspecting the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t7000 obs. of  21 variables:\n",
      " $ client_id     : int  2 3 4 5 6 7 8 9 14 15 ...\n",
      " $ age           : int  29 39 49 32 29 51 34 52 52 29 ...\n",
      " $ job           : Factor w/ 12 levels \"admin.\",\"blue-collar\",..: 4 11 2 7 1 7 2 8 1 1 ...\n",
      " $ marital       : Factor w/ 4 levels \"divorced\",\"married\",..: 3 2 2 3 3 2 2 2 2 3 ...\n",
      " $ education     : Factor w/ 8 levels \"basic.4y\",\"basic.6y\",..: 4 3 2 7 4 7 1 4 7 7 ...\n",
      " $ default       : Factor w/ 2 levels \"no\",\"unknown\": 1 2 2 1 2 2 1 1 1 1 ...\n",
      " $ housing       : Factor w/ 3 levels \"no\",\"unknown\",..: 1 3 1 3 3 3 3 3 3 3 ...\n",
      " $ loan          : Factor w/ 3 levels \"no\",\"unknown\",..: 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ contact       : Factor w/ 2 levels \"cellular\",\"telephone\": 2 2 1 1 1 2 1 1 1 1 ...\n",
      " $ month         : Factor w/ 10 levels \"apr\",\"aug\",\"dec\",..: 7 5 8 7 4 5 8 8 8 5 ...\n",
      " $ day_of_week   : Factor w/ 5 levels \"fri\",\"mon\",\"thu\",..: 2 1 4 2 1 4 4 4 3 2 ...\n",
      " $ campaign      : int  3 6 2 3 2 1 1 1 3 1 ...\n",
      " $ pdays         : int  999 999 999 999 999 999 999 999 999 999 ...\n",
      " $ previous      : int  0 0 0 1 0 0 0 0 0 0 ...\n",
      " $ poutcome      : Factor w/ 3 levels \"failure\",\"nonexistent\",..: 2 2 2 1 2 2 2 2 2 2 ...\n",
      " $ emp.var.rate  : num  1.1 1.4 -0.1 -1.8 1.4 1.4 -0.1 -0.1 -0.1 -2.9 ...\n",
      " $ cons.price.idx: num  94 94.5 93.2 92.9 93.9 ...\n",
      " $ cons.conf.idx : num  -36.4 -41.8 -42 -46.2 -42.7 -41.8 -42 -42 -42 -40.8 ...\n",
      " $ euribor3m     : num  4.86 4.96 4.15 1.3 4.96 ...\n",
      " $ nr.employed   : num  5191 5228 5196 5099 5228 ...\n",
      " $ subscribe     : int  0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "# Print out to check the data type\n",
    "str(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 One-Hot Encoding for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a list of the categorical variables\n",
    "\n",
    "cat_list <- c()  # List to store categorical variable\n",
    "\n",
    "for (v in colnames(data)) {\n",
    "    if (class(data[, v]) == 'factor') {  # Factor == categorical variable\n",
    "        cat_list <- c(cat_list, v)\n",
    "    } \n",
    "}\n",
    "\n",
    "## Loop through all categorical variables\n",
    "for (v in cat_list) {\n",
    "    \n",
    "    # Representing categorical variable \n",
    "    encoding <- build_encoding(dataSet=data, cols=v, verbose=F)\n",
    "    \n",
    "    # Apply the binning for the training data\n",
    "    data <- one_hot_encoder(dataSet=data, encoding=encoding, type='numeric', drop=T, verbose=F)\n",
    "    setDF(data)\n",
    "    data <- data[, -ncol(data)]  # Drop the last dummy column\n",
    "    \n",
    "    # Apply the binning for the prediction data\n",
    "    predict <- one_hot_encoder(dataSet=predict, encoding=encoding, type='numeric', drop=T, verbose=F)\n",
    "    setDF(predict)\n",
    "    predict <- predict[, -ncol(predict)]  # Drop the last dummy column\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Feature Engineering for Numeric Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Correct the variable: campaign\n",
    "\n",
    "Since campaign includes also the last contact, its value should be reduce by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fix the value\n",
    "data[, 'campaign'] <- data[, 'campaign'] - 1\n",
    "predict[, 'campaign'] <- predict[, 'campaign'] - 1\n",
    "\n",
    "# Quick check\n",
    "min(data[, 'campaign'])  # Previously = 1\n",
    "min(predict[, 'campaign'])  # Previously = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Checking for outliers in numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAQlBMVEUAAAAAztFIPYtNTU1m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\n2DzdisZ5mwAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"Histogram of data$nr.employed\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "par(mfrow=c(3,2))\n",
    "hist(data$age, col = \"darkorange2\")\n",
    "hist(data$emp.var.rate, col= \"darkolivegreen2\")\n",
    "hist(data$cons.price.idx, col= \"darkturquoise\")\n",
    "hist(data$cons.conf.idx, col= \"chartreuse3\")\n",
    "hist(data$euribor3m, col= \"deeppink3\")\n",
    "hist(data$nr.employed, col= \"darkslateblue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.3 Splitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "set.seed(8)\n",
    "smp_size <- floor(0.70*nrow(data))\n",
    "\n",
    "# set the seed to make your partition reproducible\n",
    "set.seed(8)\n",
    "train_ind <- sample(seq_len(nrow(data)), size = smp_size)\n",
    "\n",
    "train <- data[train_ind, ]\n",
    "test <- data[-train_ind, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.4 Treating the abnormal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train$age <- Winsorize(train$age, probs = c(0, 0.95))\n",
    "test$age <- Winsorize(test$age, probs = c(0, 0.95))\n",
    "predict$age <- Winsorize(predict$age, probs = c(0, 0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Checking for Imbalance in the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "0.88 0.12 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(prop.table(table(data$subscribe)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyL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\n1gAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tbl <- with(data, table(subscribe))\n",
    "barplot(tbl, beside = TRUE, col = \"darkred\")\n",
    "\n",
    "#Oversampling is done while setting up the cross validation process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## <center> 3. Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating missing columns in the prediction set\n",
    "dv_list <- c('subscribe')  # DV list\n",
    "std_list <- setdiff(names(train), dv_list)  # IV list excluded DV\n",
    "\n",
    "for (v in std_list){\n",
    "    if (v %notin% names(predict)) {\n",
    "        predict[,v] = 0\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_std <- train\n",
    "test_std <- test \n",
    "predict_std <- predict\n",
    "\n",
    "dv_list <- c('subscribe')  # DV list\n",
    "std_list <- setdiff(names(train_std), dv_list)  # IV list excluded DV\n",
    "std_list <- setdiff(std_list, 'client_id')  # Excluded the client_idb\n",
    "\n",
    "\n",
    "for (v in std_list) {\n",
    "    train_std[, v] <- scale(train_std[, v], center=T, scale=T)  # sd = 1, mean = 0\n",
    "    test_std[, v] <- scale(test_std[, v], center=T, scale=T)  # sd = 1, mean = 0\n",
    "    predict_std[, v] <- scale(predict_std[, v], center=T, scale=T)  # sd = 1, mean = 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## <center> 4. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "FisherScore <- function(basetable, depvar, IV_list) {\n",
    "  \n",
    "  # Get the unique values of dependent variable\n",
    "  DV <- unique(basetable[, depvar])\n",
    "  \n",
    "  IV_FisherScore <- c()\n",
    "  \n",
    "  for (v in IV_list) {\n",
    "    fs <- abs((mean(basetable[which(basetable[, depvar]==DV[1]), v]) - mean(basetable[which(basetable[, depvar]==DV[2]), v]))) /\n",
    "      sqrt((var(basetable[which(basetable[, depvar]==DV[1]), v]) + var(basetable[which(basetable[, depvar]==DV[2]), v])))\n",
    "    IV_FisherScore <- c(IV_FisherScore, fs)\n",
    "  }\n",
    "  \n",
    "  return(data.frame(IV=IV_list, fisher_score=IV_FisherScore))\n",
    "}\n",
    "\n",
    "varSelectionFisher <- function(basetable, depvar, IV_list, num_select=20) {\n",
    "  \"\n",
    "  This function will calculate the Fisher score for all IVs and select the best\n",
    "  top IVs.\n",
    "\n",
    "  Assumption: all variables of input dataset are converted into numeric type.\n",
    "  \"\n",
    "  \n",
    "  fs <- FisherScore(basetable, depvar, IV_list)  # Calculate Fisher Score for all IVs\n",
    "  num_select <- min(num_select, ncol(basetable))  # Top N IVs to be selected\n",
    "  return(as.vector(fs[order(fs$fisher_score, decreasing=T), ][1:num_select, 'IV']))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>IV</th><th scope=col>fisher_score</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>age           </td><td>0.01142089    </td></tr>\n",
       "\t<tr><td>campaign      </td><td>0.11588688    </td></tr>\n",
       "\t<tr><td>pdays         </td><td>0.43319908    </td></tr>\n",
       "\t<tr><td>previous      </td><td>0.36412613    </td></tr>\n",
       "\t<tr><td>emp.var.rate  </td><td>0.65763389    </td></tr>\n",
       "\t<tr><td>cons.price.idx</td><td>0.28478531    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " IV & fisher\\_score\\\\\n",
       "\\hline\n",
       "\t age            & 0.01142089    \\\\\n",
       "\t campaign       & 0.11588688    \\\\\n",
       "\t pdays          & 0.43319908    \\\\\n",
       "\t previous       & 0.36412613    \\\\\n",
       "\t emp.var.rate   & 0.65763389    \\\\\n",
       "\t cons.price.idx & 0.28478531    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| IV | fisher_score |\n",
       "|---|---|\n",
       "| age            | 0.01142089     |\n",
       "| campaign       | 0.11588688     |\n",
       "| pdays          | 0.43319908     |\n",
       "| previous       | 0.36412613     |\n",
       "| emp.var.rate   | 0.65763389     |\n",
       "| cons.price.idx | 0.28478531     |\n",
       "\n"
      ],
      "text/plain": [
       "  IV             fisher_score\n",
       "1 age            0.01142089  \n",
       "2 campaign       0.11588688  \n",
       "3 pdays          0.43319908  \n",
       "4 previous       0.36412613  \n",
       "5 emp.var.rate   0.65763389  \n",
       "6 cons.price.idx 0.28478531  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Fisher Score for all variable\n",
    "# Get the IV and DV list\n",
    "dv_list <- c('subscribe')  # DV list\n",
    "iv_list <- setdiff(names(train), dv_list)  # IV list excluded DV\n",
    "iv_list <- setdiff(iv_list, 'client_id')  # Excluded the client_id\n",
    "fs <- FisherScore(train, dv_list, iv_list)\n",
    "head(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'nr.employed'</li>\n",
       "\t<li>'euribor3m'</li>\n",
       "\t<li>'emp.var.rate'</li>\n",
       "\t<li>'pdays'</li>\n",
       "\t<li>'contact.cellular'</li>\n",
       "\t<li>'previous'</li>\n",
       "\t<li>'poutcome.nonexistent'</li>\n",
       "\t<li>'cons.price.idx'</li>\n",
       "\t<li>'month.may'</li>\n",
       "\t<li>'month.oct'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'nr.employed'\n",
       "\\item 'euribor3m'\n",
       "\\item 'emp.var.rate'\n",
       "\\item 'pdays'\n",
       "\\item 'contact.cellular'\n",
       "\\item 'previous'\n",
       "\\item 'poutcome.nonexistent'\n",
       "\\item 'cons.price.idx'\n",
       "\\item 'month.may'\n",
       "\\item 'month.oct'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'nr.employed'\n",
       "2. 'euribor3m'\n",
       "3. 'emp.var.rate'\n",
       "4. 'pdays'\n",
       "5. 'contact.cellular'\n",
       "6. 'previous'\n",
       "7. 'poutcome.nonexistent'\n",
       "8. 'cons.price.idx'\n",
       "9. 'month.may'\n",
       "10. 'month.oct'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"nr.employed\"          \"euribor3m\"            \"emp.var.rate\"        \n",
       " [4] \"pdays\"                \"contact.cellular\"     \"previous\"            \n",
       " [7] \"poutcome.nonexistent\" \"cons.price.idx\"       \"month.may\"           \n",
       "[10] \"month.oct\"           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select top 20 variables according to the Fisher Score\n",
    "best_fs_var <- varSelectionFisher(train, dv_list, iv_list, num_select=20)\n",
    "head(best_fs_var, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply variable selection to the data\n",
    "# Train\n",
    "var_select <- names(train)[names(train) %in% best_fs_var]\n",
    "train_processed <- train[, c('client_id', var_select, 'subscribe')]\n",
    "train_processed_std <- train_std[, c('client_id', var_select, 'subscribe')]  #standardised train set\n",
    "\n",
    "# Test\n",
    "var_select <- names(test)[names(test) %in% best_fs_var]\n",
    "test_processed <- test[, c('client_id', var_select, 'subscribe')]\n",
    "test_processed_std <- test_std[, c('client_id', var_select, 'subscribe')]    #standardised test set\n",
    "\n",
    "# Predict\n",
    "var_select <- names(test)[names(test) %in% best_fs_var]\n",
    "predict_processed <- predict[, c('client_id', var_select)]\n",
    "predict_processed_std <- predict_std[, c('client_id', var_select)]           #standardised prediction set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## <center> 4. Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training the model and testing its performance\n",
    "glm.fit = glm(subscribe~.,family=binomial(link='logit'),data=train_processed_std)\n",
    "p_test <- predict(glm.fit, newdata=test_processed_std, type=\"response\")\n",
    "\n",
    "#Running the model on the Holdout Set\n",
    "predicted.results = predict(glm.fit,newdata=predict_processed_std, type = \"response\")\n",
    "predicted.results = data.frame(predicted.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.810117168161054"
      ],
      "text/latex": [
       "0.810117168161054"
      ],
      "text/markdown": [
       "0.810117168161054"
      ],
      "text/plain": [
       "[1] 0.8101172"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Evaluating the Performance of the Model \n",
    "pr <- prediction(p_test, test_processed$subscribe)\n",
    "prf <- ROCR::performance(pr, measure = \"tpr\", x.measure = \"fpr\")\n",
    "#plot(prf)\n",
    "\n",
    "auc <- ROCR::performance(pr, measure = \"auc\")\n",
    "auc <- auc@y.values[[1]]\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune] Started tuning learner classif.randomForest for parameter set:\n",
      "          Type len Def               Constr Req Tunable Trafo\n",
      "ntree discrete   -   - 100,250,500,750,1000   -    TRUE     -\n",
      "mtry  discrete   -   -          1,2,3,5,6,9   -    TRUE     -\n",
      "With control class: TuneControlGrid\n",
      "Imputation value: -0\n",
      "[Tune-x] 1: ntree=100; mtry=1\n",
      "[Tune-y] 1: auc.test.mean=0.7393914; time: 0.0 min\n",
      "[Tune-x] 2: ntree=250; mtry=1\n",
      "[Tune-y] 2: auc.test.mean=0.7482690; time: 0.1 min\n",
      "[Tune-x] 3: ntree=500; mtry=1\n",
      "[Tune-y] 3: auc.test.mean=0.7508351; time: 0.1 min\n",
      "[Tune-x] 4: ntree=750; mtry=1\n",
      "[Tune-y] 4: auc.test.mean=0.7547151; time: 0.2 min\n",
      "[Tune-x] 5: ntree=1000; mtry=1\n",
      "[Tune-y] 5: auc.test.mean=0.7555304; time: 0.2 min\n",
      "[Tune-x] 6: ntree=100; mtry=2\n",
      "[Tune-y] 6: auc.test.mean=0.7629422; time: 0.0 min\n",
      "[Tune-x] 7: ntree=250; mtry=2\n",
      "[Tune-y] 7: auc.test.mean=0.7585109; time: 0.1 min\n",
      "[Tune-x] 8: ntree=500; mtry=2\n",
      "[Tune-y] 8: auc.test.mean=0.7641980; time: 0.2 min\n",
      "[Tune-x] 9: ntree=750; mtry=2\n",
      "[Tune-y] 9: auc.test.mean=0.7652958; time: 0.2 min\n",
      "[Tune-x] 10: ntree=1000; mtry=2\n",
      "[Tune-y] 10: auc.test.mean=0.7662359; time: 0.3 min\n",
      "[Tune-x] 11: ntree=100; mtry=3\n",
      "[Tune-y] 11: auc.test.mean=0.7568587; time: 0.0 min\n",
      "[Tune-x] 12: ntree=250; mtry=3\n",
      "[Tune-y] 12: auc.test.mean=0.7582354; time: 0.1 min\n",
      "[Tune-x] 13: ntree=500; mtry=3\n",
      "[Tune-y] 13: auc.test.mean=0.7658181; time: 0.2 min\n",
      "[Tune-x] 14: ntree=750; mtry=3\n",
      "[Tune-y] 14: auc.test.mean=0.7748251; time: 0.3 min\n",
      "[Tune-x] 15: ntree=1000; mtry=3\n",
      "[Tune-y] 15: auc.test.mean=0.7733795; time: 0.4 min\n",
      "[Tune-x] 16: ntree=100; mtry=5\n",
      "[Tune-y] 16: auc.test.mean=0.7665453; time: 0.0 min\n",
      "[Tune-x] 17: ntree=250; mtry=5\n",
      "[Tune-y] 17: auc.test.mean=0.7686633; time: 0.1 min\n",
      "[Tune-x] 18: ntree=500; mtry=5\n",
      "[Tune-y] 18: auc.test.mean=0.7726524; time: 0.2 min\n",
      "[Tune-x] 19: ntree=750; mtry=5\n",
      "[Tune-y] 19: auc.test.mean=0.7755929; time: 0.3 min\n",
      "[Tune-x] 20: ntree=1000; mtry=5\n",
      "[Tune-y] 20: auc.test.mean=0.7788091; time: 0.5 min\n",
      "[Tune-x] 21: ntree=100; mtry=6\n",
      "[Tune-y] 21: auc.test.mean=0.7694612; time: 0.0 min\n",
      "[Tune-x] 22: ntree=250; mtry=6\n",
      "[Tune-y] 22: auc.test.mean=0.7668783; time: 0.1 min\n",
      "[Tune-x] 23: ntree=500; mtry=6\n",
      "[Tune-y] 23: auc.test.mean=0.7750762; time: 0.2 min\n",
      "[Tune-x] 24: ntree=750; mtry=6\n",
      "[Tune-y] 24: auc.test.mean=0.7765543; time: 0.4 min\n",
      "[Tune-x] 25: ntree=1000; mtry=6\n",
      "[Tune-y] 25: auc.test.mean=0.7778019; time: 0.5 min\n",
      "[Tune-x] 26: ntree=100; mtry=9\n",
      "[Tune-y] 26: auc.test.mean=0.7644868; time: 0.1 min\n",
      "[Tune-x] 27: ntree=250; mtry=9\n",
      "[Tune-y] 27: auc.test.mean=0.7697399; time: 0.1 min\n",
      "[Tune-x] 28: ntree=500; mtry=9\n",
      "[Tune-y] 28: auc.test.mean=0.7689136; time: 0.3 min\n",
      "[Tune-x] 29: ntree=750; mtry=9\n",
      "[Tune-y] 29: auc.test.mean=0.7704610; time: 0.4 min\n",
      "[Tune-x] 30: ntree=1000; mtry=9\n",
      "[Tune-y] 30: auc.test.mean=0.7719378; time: 0.5 min\n",
      "[Tune] Result: ntree=1000; mtry=5 : auc.test.mean=0.7788091\n"
     ]
    }
   ],
   "source": [
    "# Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=5)\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.randomForest\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    "  makeDiscreteParam('ntree', value=c(100, 250, 500, 750, 1000)),\n",
    "  makeDiscreteParam('mtry', value=round(sqrt((ncol(train_processed)-1) * c(0.1, 0.25, 0.5, 1, 2, 4))))\n",
    ")\n",
    "ctrl = makeTuneControlGrid()\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "     par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.791140326750646"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.791140326750646"
      ],
      "text/markdown": [
       "**auc:** 0.791140326750646"
      ],
      "text/plain": [
       "      auc \n",
       "0.7911403 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "best_md <- mlr::train(best_learner, train_task)\n",
    "\n",
    "# Make prediction on valid data\n",
    "pred <- predict(best_md, newdata=test_processed[, -1])\n",
    "mlr::performance(pred, measures= mlr::auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune] Started tuning learner classif.kknn for parameter set:\n",
      "      Type len Def                            Constr Req Tunable Trafo\n",
      "k discrete   -   - 2,3,4,5,6,7,8,9,10,11,12,13,14,15   -    TRUE     -\n",
      "With control class: TuneControlGrid\n",
      "Imputation value: -0\n",
      "[Tune-x] 1: k=2\n",
      "[Tune-y] 1: auc.test.mean=0.6856570; time: 0.0 min\n",
      "[Tune-x] 2: k=3\n",
      "[Tune-y] 2: auc.test.mean=0.7061354; time: 0.0 min\n",
      "[Tune-x] 3: k=4\n",
      "[Tune-y] 3: auc.test.mean=0.7180844; time: 0.0 min\n",
      "[Tune-x] 4: k=5\n",
      "[Tune-y] 4: auc.test.mean=0.7274098; time: 0.0 min\n",
      "[Tune-x] 5: k=6\n",
      "[Tune-y] 5: auc.test.mean=0.7349128; time: 0.0 min\n",
      "[Tune-x] 6: k=7\n",
      "[Tune-y] 6: auc.test.mean=0.7402761; time: 0.0 min\n",
      "[Tune-x] 7: k=8\n",
      "[Tune-y] 7: auc.test.mean=0.7413902; time: 0.0 min\n",
      "[Tune-x] 8: k=9\n",
      "[Tune-y] 8: auc.test.mean=0.7448776; time: 0.0 min\n",
      "[Tune-x] 9: k=10\n",
      "[Tune-y] 9: auc.test.mean=0.7452591; time: 0.0 min\n",
      "[Tune-x] 10: k=11\n",
      "[Tune-y] 10: auc.test.mean=0.7494795; time: 0.0 min\n",
      "[Tune-x] 11: k=12\n",
      "[Tune-y] 11: auc.test.mean=0.7527436; time: 0.0 min\n",
      "[Tune-x] 12: k=13\n",
      "[Tune-y] 12: auc.test.mean=0.7548665; time: 0.0 min\n",
      "[Tune-x] 13: k=14\n",
      "[Tune-y] 13: auc.test.mean=0.7588876; time: 0.0 min\n",
      "[Tune-x] 14: k=15\n",
      "[Tune-y] 14: auc.test.mean=0.7584501; time: 0.0 min\n",
      "[Tune] Result: k=14 : auc.test.mean=0.7588876\n"
     ]
    }
   ],
   "source": [
    "# Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=10)\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.kknn\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    "    makeDiscreteParam('k', value=c(2:15))\n",
    ")\n",
    "ctrl = makeTuneControlGrid()\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "     par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.742222344463392"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.742222344463392"
      ],
      "text/markdown": [
       "**auc:** 0.742222344463392"
      ],
      "text/plain": [
       "      auc \n",
       "0.7422223 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "best_md <- mlr::train(best_learner, train_task)\n",
    "\n",
    "# Make prediction on valid data\n",
    "pred <- predict(best_md, newdata=test_processed[, -1])\n",
    "mlr::performance(pred, measures= mlr::auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling: cross-validation\n",
      "Measures:             auc       \n",
      "[Resample] iter 1:    0.7915663 \n",
      "[Resample] iter 2:    0.8019344 \n",
      "[Resample] iter 3:    0.7728774 \n",
      "[Resample] iter 4:    0.8114542 \n",
      "[Resample] iter 5:    0.8007002 \n",
      "[Resample] iter 6:    0.7371684 \n",
      "[Resample] iter 7:    0.7781523 \n",
      "[Resample] iter 8:    0.7524611 \n",
      "[Resample] iter 9:    0.7478682 \n",
      "[Resample] iter 10:   0.7768932 \n",
      "\n",
      "\n",
      "Aggregated Result: auc.test.mean=0.7771076\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=10)\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.lda\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    ")\n",
    "ctrl = makeTuneControlGrid()\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "     par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.801261895593817"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.801261895593817"
      ],
      "text/markdown": [
       "**auc:** 0.801261895593817"
      ],
      "text/plain": [
       "      auc \n",
       "0.8012619 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "best_md <- mlr::train(best_learner, train_task)\n",
    "\n",
    "# Make prediction on valid data\n",
    "pred <- predict(best_md, newdata=test_processed[, -1])\n",
    "mlr::performance(pred, measures= mlr::auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 QDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling: cross-validation\n",
      "Measures:             auc       \n",
      "[Resample] iter 1:    0.7723700 \n",
      "[Resample] iter 2:    0.7414267 \n",
      "[Resample] iter 3:    0.7600418 \n",
      "[Resample] iter 4:    0.7756753 \n",
      "[Resample] iter 5:    0.7609568 \n",
      "[Resample] iter 6:    0.7654842 \n",
      "[Resample] iter 7:    0.7602867 \n",
      "[Resample] iter 8:    0.7809415 \n",
      "[Resample] iter 9:    0.8376484 \n",
      "[Resample] iter 10:   0.7763439 \n",
      "\n",
      "\n",
      "Aggregated Result: auc.test.mean=0.7731175\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=10)\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.qda\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    ")\n",
    "ctrl = makeTuneControlGrid()\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "     par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.802958358545575"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.802958358545575"
      ],
      "text/markdown": [
       "**auc:** 0.802958358545575"
      ],
      "text/plain": [
       "      auc \n",
       "0.8029584 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "best_md <- mlr::train(best_learner, train_task)\n",
    "\n",
    "# Make prediction on valid data\n",
    "pred <- predict(best_md, newdata=test_processed[, -1])\n",
    "mlr::performance(pred, measures= mlr::auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune] Started tuning learner classif.xgboost for parameter set:\n",
      "                     Type len Def            Constr Req Tunable Trafo\n",
      "gamma            discrete   -   - 0,0.1,0.2,0.3,0.4   -    TRUE     -\n",
      "min_child_weight discrete   -   -           1,3,5,7   -    TRUE     -\n",
      "With control class: TuneControlGrid\n",
      "Imputation value: -0\n",
      "[Tune-x] 1: gamma=0; min_child_weight=1\n",
      "[Tune-y] 1: auc.test.mean=0.7651838; time: 0.0 min\n",
      "[Tune-x] 2: gamma=0.1; min_child_weight=1\n",
      "[Tune-y] 2: auc.test.mean=0.7651640; time: 0.0 min\n",
      "[Tune-x] 3: gamma=0.2; min_child_weight=1\n",
      "[Tune-y] 3: auc.test.mean=0.7651671; time: 0.0 min\n",
      "[Tune-x] 4: gamma=0.3; min_child_weight=1\n",
      "[Tune-y] 4: auc.test.mean=0.7649555; time: 0.0 min\n",
      "[Tune-x] 5: gamma=0.4; min_child_weight=1\n",
      "[Tune-y] 5: auc.test.mean=0.7649835; time: 0.0 min\n",
      "[Tune-x] 6: gamma=0; min_child_weight=3\n",
      "[Tune-y] 6: auc.test.mean=0.7609404; time: 0.0 min\n",
      "[Tune-x] 7: gamma=0.1; min_child_weight=3\n",
      "[Tune-y] 7: auc.test.mean=0.7609034; time: 0.0 min\n",
      "[Tune-x] 8: gamma=0.2; min_child_weight=3\n",
      "[Tune-y] 8: auc.test.mean=0.7610078; time: 0.0 min\n",
      "[Tune-x] 9: gamma=0.3; min_child_weight=3\n",
      "[Tune-y] 9: auc.test.mean=0.7608091; time: 0.0 min\n",
      "[Tune-x] 10: gamma=0.4; min_child_weight=3\n",
      "[Tune-y] 10: auc.test.mean=0.7608126; time: 0.0 min\n",
      "[Tune-x] 11: gamma=0; min_child_weight=5\n",
      "[Tune-y] 11: auc.test.mean=0.7642416; time: 0.0 min\n",
      "[Tune-x] 12: gamma=0.1; min_child_weight=5\n",
      "[Tune-y] 12: auc.test.mean=0.7642416; time: 0.0 min\n",
      "[Tune-x] 13: gamma=0.2; min_child_weight=5\n",
      "[Tune-y] 13: auc.test.mean=0.7643353; time: 0.0 min\n",
      "[Tune-x] 14: gamma=0.3; min_child_weight=5\n",
      "[Tune-y] 14: auc.test.mean=0.7642796; time: 0.0 min\n",
      "[Tune-x] 15: gamma=0.4; min_child_weight=5\n",
      "[Tune-y] 15: auc.test.mean=0.7641302; time: 0.0 min\n",
      "[Tune-x] 16: gamma=0; min_child_weight=7\n",
      "[Tune-y] 16: auc.test.mean=0.7640333; time: 0.0 min\n",
      "[Tune-x] 17: gamma=0.1; min_child_weight=7\n",
      "[Tune-y] 17: auc.test.mean=0.7640729; time: 0.0 min\n",
      "[Tune-x] 18: gamma=0.2; min_child_weight=7\n",
      "[Tune-y] 18: auc.test.mean=0.7641553; time: 0.0 min\n",
      "[Tune-x] 19: gamma=0.3; min_child_weight=7\n",
      "[Tune-y] 19: auc.test.mean=0.7641553; time: 0.0 min\n",
      "[Tune-x] 20: gamma=0.4; min_child_weight=7\n",
      "[Tune-y] 20: auc.test.mean=0.7638779; time: 0.0 min\n",
      "[Tune] Result: gamma=0; min_child_weight=1 : auc.test.mean=0.7651838\n"
     ]
    }
   ],
   "source": [
    "# Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=10)\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.xgboost\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    "    #makeDiscreteParam('max.depth', value=c(3, 4, 5, 6, 8, 10, 12, 15)),\n",
    "    makeDiscreteParam('gamma', value=c(0.0, 0.1, 0.2 , 0.3, 0.4)),\n",
    "    makeDiscreteParam('min_child_weight', value=c(1, 3, 5, 7))\n",
    ")\n",
    "ctrl = makeTuneControlGrid()\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "     par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.783695472798284"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.783695472798284"
      ],
      "text/markdown": [
       "**auc:** 0.783695472798284"
      ],
      "text/plain": [
       "      auc \n",
       "0.7836955 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "best_md <- mlr::train(best_learner, train_task)\n",
    "\n",
    "# Make prediction on valid data\n",
    "pred <- predict(best_md, newdata=test_processed[, -1])\n",
    "mlr::performance(pred, measures= mlr::auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune] Started tuning learner classif.svm for parameter set:\n",
      "          Type len Def                                   Constr Req Tunable\n",
      "gamma discrete   -   -                                        0   -    TRUE\n",
      "cost  discrete   -   - 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,1...   -    TRUE\n",
      "      Trafo\n",
      "gamma     -\n",
      "cost      -\n",
      "With control class: TuneControlGrid\n",
      "Imputation value: -0\n",
      "[Tune-x] 1: gamma=0; cost=1\n",
      "[Tune-y] 1: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 2: gamma=0; cost=2\n",
      "[Tune-y] 2: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 3: gamma=0; cost=3\n",
      "[Tune-y] 3: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 4: gamma=0; cost=4\n",
      "[Tune-y] 4: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 5: gamma=0; cost=5\n",
      "[Tune-y] 5: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 6: gamma=0; cost=6\n",
      "[Tune-y] 6: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 7: gamma=0; cost=7\n",
      "[Tune-y] 7: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 8: gamma=0; cost=8\n",
      "[Tune-y] 8: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 9: gamma=0; cost=9\n",
      "[Tune-y] 9: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 10: gamma=0; cost=10\n",
      "[Tune-y] 10: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 11: gamma=0; cost=11\n",
      "[Tune-y] 11: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 12: gamma=0; cost=12\n",
      "[Tune-y] 12: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 13: gamma=0; cost=13\n",
      "[Tune-y] 13: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 14: gamma=0; cost=14\n",
      "[Tune-y] 14: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 15: gamma=0; cost=15\n",
      "[Tune-y] 15: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 16: gamma=0; cost=16\n",
      "[Tune-y] 16: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 17: gamma=0; cost=17\n",
      "[Tune-y] 17: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 18: gamma=0; cost=18\n",
      "[Tune-y] 18: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 19: gamma=0; cost=19\n",
      "[Tune-y] 19: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 20: gamma=0; cost=20\n",
      "[Tune-y] 20: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 21: gamma=0; cost=21\n",
      "[Tune-y] 21: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 22: gamma=0; cost=22\n",
      "[Tune-y] 22: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 23: gamma=0; cost=23\n",
      "[Tune-y] 23: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 24: gamma=0; cost=24\n",
      "[Tune-y] 24: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 25: gamma=0; cost=25\n",
      "[Tune-y] 25: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 26: gamma=0; cost=26\n",
      "[Tune-y] 26: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 27: gamma=0; cost=27\n",
      "[Tune-y] 27: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 28: gamma=0; cost=28\n",
      "[Tune-y] 28: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 29: gamma=0; cost=29\n",
      "[Tune-y] 29: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 30: gamma=0; cost=30\n",
      "[Tune-y] 30: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 31: gamma=0; cost=31\n",
      "[Tune-y] 31: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 32: gamma=0; cost=32\n",
      "[Tune-y] 32: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 33: gamma=0; cost=33\n",
      "[Tune-y] 33: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 34: gamma=0; cost=34\n",
      "[Tune-y] 34: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 35: gamma=0; cost=35\n",
      "[Tune-y] 35: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 36: gamma=0; cost=36\n",
      "[Tune-y] 36: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 37: gamma=0; cost=37\n",
      "[Tune-y] 37: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 38: gamma=0; cost=38\n",
      "[Tune-y] 38: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 39: gamma=0; cost=39\n",
      "[Tune-y] 39: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 40: gamma=0; cost=40\n",
      "[Tune-y] 40: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 41: gamma=0; cost=41\n",
      "[Tune-y] 41: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 42: gamma=0; cost=42\n",
      "[Tune-y] 42: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 43: gamma=0; cost=43\n",
      "[Tune-y] 43: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 44: gamma=0; cost=44\n",
      "[Tune-y] 44: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 45: gamma=0; cost=45\n",
      "[Tune-y] 45: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 46: gamma=0; cost=46\n",
      "[Tune-y] 46: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 47: gamma=0; cost=47\n",
      "[Tune-y] 47: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 48: gamma=0; cost=48\n",
      "[Tune-y] 48: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 49: gamma=0; cost=49\n",
      "[Tune-y] 49: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 50: gamma=0; cost=50\n",
      "[Tune-y] 50: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 51: gamma=0; cost=51\n",
      "[Tune-y] 51: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 52: gamma=0; cost=52\n",
      "[Tune-y] 52: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 53: gamma=0; cost=53\n",
      "[Tune-y] 53: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 54: gamma=0; cost=54\n",
      "[Tune-y] 54: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 55: gamma=0; cost=55\n",
      "[Tune-y] 55: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 56: gamma=0; cost=56\n",
      "[Tune-y] 56: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 57: gamma=0; cost=57\n",
      "[Tune-y] 57: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 58: gamma=0; cost=58\n",
      "[Tune-y] 58: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 59: gamma=0; cost=59\n",
      "[Tune-y] 59: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 60: gamma=0; cost=60\n",
      "[Tune-y] 60: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 61: gamma=0; cost=61\n",
      "[Tune-y] 61: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 62: gamma=0; cost=62\n",
      "[Tune-y] 62: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 63: gamma=0; cost=63\n",
      "[Tune-y] 63: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 64: gamma=0; cost=64\n",
      "[Tune-y] 64: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 65: gamma=0; cost=65\n",
      "[Tune-y] 65: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 66: gamma=0; cost=66\n",
      "[Tune-y] 66: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 67: gamma=0; cost=67\n",
      "[Tune-y] 67: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 68: gamma=0; cost=68\n",
      "[Tune-y] 68: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 69: gamma=0; cost=69\n",
      "[Tune-y] 69: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 70: gamma=0; cost=70\n",
      "[Tune-y] 70: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 71: gamma=0; cost=71\n",
      "[Tune-y] 71: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 72: gamma=0; cost=72\n",
      "[Tune-y] 72: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 73: gamma=0; cost=73\n",
      "[Tune-y] 73: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 74: gamma=0; cost=74\n",
      "[Tune-y] 74: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 75: gamma=0; cost=75\n",
      "[Tune-y] 75: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 76: gamma=0; cost=76\n",
      "[Tune-y] 76: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 77: gamma=0; cost=77\n",
      "[Tune-y] 77: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 78: gamma=0; cost=78\n",
      "[Tune-y] 78: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 79: gamma=0; cost=79\n",
      "[Tune-y] 79: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 80: gamma=0; cost=80\n",
      "[Tune-y] 80: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 81: gamma=0; cost=81\n",
      "[Tune-y] 81: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 82: gamma=0; cost=82\n",
      "[Tune-y] 82: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 83: gamma=0; cost=83\n",
      "[Tune-y] 83: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 84: gamma=0; cost=84\n",
      "[Tune-y] 84: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 85: gamma=0; cost=85\n",
      "[Tune-y] 85: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 86: gamma=0; cost=86\n",
      "[Tune-y] 86: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 87: gamma=0; cost=87\n",
      "[Tune-y] 87: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 88: gamma=0; cost=88\n",
      "[Tune-y] 88: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 89: gamma=0; cost=89\n",
      "[Tune-y] 89: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 90: gamma=0; cost=90\n",
      "[Tune-y] 90: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 91: gamma=0; cost=91\n",
      "[Tune-y] 91: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 92: gamma=0; cost=92\n",
      "[Tune-y] 92: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 93: gamma=0; cost=93\n",
      "[Tune-y] 93: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 94: gamma=0; cost=94\n",
      "[Tune-y] 94: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 95: gamma=0; cost=95\n",
      "[Tune-y] 95: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 96: gamma=0; cost=96\n",
      "[Tune-y] 96: auc.test.mean=0.5000000; time: 0.2 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tune-x] 97: gamma=0; cost=97\n",
      "[Tune-y] 97: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 98: gamma=0; cost=98\n",
      "[Tune-y] 98: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 99: gamma=0; cost=99\n",
      "[Tune-y] 99: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune-x] 100: gamma=0; cost=100\n",
      "[Tune-y] 100: auc.test.mean=0.5000000; time: 0.2 min\n",
      "[Tune] Result: gamma=0; cost=32 : auc.test.mean=0.5000000\n"
     ]
    }
   ],
   "source": [
    "# Set up cross-validation\n",
    "rdesc = makeResampleDesc(\"CV\", iters=10)\n",
    "\n",
    "# Define the model\n",
    "learner <- makeLearner(\"classif.svm\", predict.type=\"prob\", fix.factors.prediction=T)\n",
    "\n",
    "# Define the task\n",
    "train_task <- makeClassifTask(id=\"bank_train\", data=train_processed[, -1], target=\"subscribe\")\n",
    "\n",
    "# Set hyper parameter tuning\n",
    "tune_params <- makeParamSet(\n",
    "    #makeDiscreteParam('max.depth', value=c(3, 4, 5, 6, 8, 10, 12, 15)),\n",
    "    makeDiscreteParam('gamma', value=c(0.0:0.4)),\n",
    "    makeDiscreteParam('cost', value=c(1:100))\n",
    ")\n",
    "ctrl = makeTuneControlGrid()\n",
    "\n",
    "# Run the hyper parameter tuning with k-fold CV\n",
    "if (length(tune_params$pars) > 0) {\n",
    "    # Run parameter tuning\n",
    "    res <- tuneParams(learner, task=train_task, resampling=rdesc,\n",
    "     par.set=tune_params, control=ctrl, measures=list(mlr::auc))\n",
    "    \n",
    "    # Extract best model\n",
    "    best_learner <- res$learner\n",
    "    \n",
    "} else {\n",
    "    # Simple cross-validation\n",
    "    res <- resample(learner, train_task, rdesc, measures=list(mlr::auc))\n",
    "    \n",
    "    # No parameter for tuning, only 1 best learner\n",
    "    best_learner <- learner\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>auc:</strong> 0.734210902689917"
      ],
      "text/latex": [
       "\\textbf{auc:} 0.734210902689917"
      ],
      "text/markdown": [
       "**auc:** 0.734210902689917"
      ],
      "text/plain": [
       "      auc \n",
       "0.7342109 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrain the model with tbe best hyper-parameters\n",
    "best_md <- mlr::train(best_learner, train_task)\n",
    "\n",
    "# Make prediction on valid data\n",
    "pred <- predict(best_md, newdata=test_processed[, -1])\n",
    "mlr::performance(pred, measures= mlr::auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the predictions of the logistic regression model \n",
    "#write.csv(predicted.results ,\"PredictionsToSubmit.csv\", row.names = FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
